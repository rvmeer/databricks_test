{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5be080b-a3bf-4708-9282-8b1d595fbacc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "          select * from motar_asml.logging.cpdt_logging_silver\n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74bea1cf-0545-4cc1-a939-29be07e31870",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Determine the features (feature_name column)\n",
    "from pyspark.sql.functions import when, col, lit\n",
    "\n",
    "feature_dict = {\n",
    "    \"Classic\" : ['MATLAB'],\n",
    "    \"Vcraft\" : ['vcraft'],\n",
    "    \"Python remote debugging\": ['devbenchExtension', 'Debugger attached successfully'],\n",
    "    \"Python remote debugging old\": ['cidtDebugSession', 'Cidt debug session initialized'],\n",
    "    \"Devbench sync\": ['devbenchExtension', 'Adding filewatcher for'],\n",
    "    \"Devbench sync old\": ['devbenchExtension', 'Performing post-copy actions'],\n",
    "    \"Devbench integration\": ['devbenchExtension', 'Devbench','successfully created'],\n",
    "    \"Report preview\": ['reportPreviewExtension'],\n",
    "    \"Report editor\": ['reportEditor'],\n",
    "    \"DDF syntax checking\": ['ddfCheckerExtension', \"Checker\"], # \"Checker found an error\"\n",
    "    \"DDF jump around\": ['ddfDefinitionProvider'],   # no extra filter needed: Definition found for ...\n",
    "    \"CPD aspects overview\": ['aspectsExtension'],\n",
    "    \"Required interfaces viewer\": ['ddfFileTreeExtension'],\n",
    "    \"Requirements editor flow\": ['flowEditor'],\n",
    "    \"Requirements editor step\": ['stepEditor'],\n",
    "    \"ER eventlog viewer\": ['devbenchExtension', 'Spawning ssh tail process for', 'on ER/ER_event_log'],\n",
    "    \"Live sync\": ['devbenchExtension', 'Live sync enabled for'],\n",
    "    \"Swipe integration\": ['swipeExtension']\n",
    "}\n",
    "\n",
    "df = df.withColumn(\"feature_name\", lit(\"\"))\n",
    "\n",
    "for feature in feature_dict:\n",
    "    print(f'Handling feature {feature}')\n",
    "    filters = feature_dict[feature]\n",
    "\n",
    "    extension = filters[0]\n",
    "\n",
    "    feature_name = feature\n",
    "    if feature_name == 'Devbench sync old':\n",
    "        feature_name = 'Devbench sync'\n",
    "    elif feature_name == 'Python remote debugging old':\n",
    "        feature_name = 'Python remote debugging'\n",
    "\n",
    "    if len(filters) == 1:\n",
    "        df = df.withColumn(\n",
    "            \"feature_name\",\n",
    "            when(col(\"logger\") == extension, lit(feature_name)).otherwise(col(\"feature_name\"))\n",
    "        )\n",
    "    elif len(filters) == 2:\n",
    "        df = df.withColumn(\n",
    "            \"feature_name\",\n",
    "            when(\n",
    "                (col(\"logger\") == extension) & (col(\"message\").contains(filters[1])),\n",
    "                lit(feature_name)\n",
    "            ).otherwise(col(\"feature_name\"))\n",
    "        )\n",
    "    elif len(filters) == 3:\n",
    "        df = df.withColumn(\n",
    "            \"feature_name\",\n",
    "            when((col(\"logger\") == extension) & \n",
    "                   (col(\"message\").contains(filters[1])) & \n",
    "                   (col(\"message\").contains(filters[2])), lit(feature_name)).otherwise(col(\"feature_name\"))\n",
    "        )\n",
    "    count = df.where(f\"feature_name == '{feature_name}'\").count()\n",
    "    print(f\"Count of {feature_name}\", count)\n",
    "    \n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1abe22c4-6057-43c9-a93c-d99f227b0a34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Count the number of unique_days for a feature (feature_unique_days_used)\n",
    "# Will be 0 if no feature is determined for the log line.\n",
    "from pyspark.sql.functions import date_trunc, countDistinct\n",
    "\n",
    "# Count the number of unique days a user for a certain CPD uses a feature\n",
    "unique_days = df.groupBy(\"feature_name\", \"cpd_name\", \"user\") \\\n",
    "    .agg(\n",
    "        countDistinct(date_trunc(\"day\", col(\"time\").cast(\"timestamp\"))).alias(\"feature_unique_days_used\")\n",
    "    ) \\\n",
    "    .withColumnRenamed(\"feature_name\", \"ud_feature_name\") \\\n",
    "    .withColumnRenamed(\"user\", \"ud_user\") \\\n",
    "    .withColumnRenamed(\"cpd_name\", \"ud_cpd_name\")\n",
    "\n",
    "\n",
    "display(unique_days)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "689f8a9d-cf10-42d7-a2d1-68796046cfba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop('feature_unique_days_used')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bffc155-b4c1-4c2f-afd6-b03506f8a3a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6648bcfd-5958-40be-9eb8-e2ecbee7ff29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Join\n",
    "df = df.drop('feature_unique_days_used')\n",
    "df = df.join(\n",
    "    unique_days, \n",
    "    (df.feature_name == unique_days.ud_feature_name) & (df.cpd_name == unique_days.ud_cpd_name) & (df.user == unique_days.ud_user), \n",
    "    how=\"left\"\n",
    ").withColumn(\n",
    "    \"feature_unique_days_used\",\n",
    "    when(\n",
    "        (col(\"ud_feature_name\").isNull()) | (col(\"ud_feature_name\") == \"\"), \n",
    "        0\n",
    "    ).otherwise(col(\"feature_unique_days_used\"))\n",
    ")\n",
    "\n",
    "# Drop the name column\n",
    "df = df.drop('ud_feature_name')\n",
    "df = df.drop('ud_cpd_name')\n",
    "df = df.drop('ud_user')\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9ccadce-7354-4395-95f9-d234e5ac7b55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write the cpdt_logging_silver and make sure if columns are added to the target, this is added as an optiona\n",
    "df.write.format(\"delta\").mode(\"overwrite\").option(\"mergeSchema\",\"true\").saveAsTable(\"motar_asml.logging.cpdt_logging_silver\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Determine features",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
